{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Djinho/Djinho.github.io/blob/main/project_notebook_8th.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCVVjCmuyk6W"
      },
      "source": [
        "# Tutorial for binary classification using _ImaGene_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbm4-myiyk6Z"
      },
      "source": [
        "This is a short tutorial to learn the basic usage of _ImaGene_ which contains a series of objects in _python_ to interact with _keras_.\n",
        "\n",
        "In this example our aim is to predict whether a given locus is under natural selection from population genomic data.\n",
        "Therefore, we will use _ImaGene_ to perform a binary classification and we will use the classic example of positive selection for lactase persistence in human populations.\n",
        "\n",
        "The C/T(-13910) variant, or rs4988235, is located on chromosome 2 in the _MCM6_ gene but influences the lactase _LCT_ gene. This SNP is associated with the primary haplotype associated with lactose intolerance in European populations.\n",
        "In these populations, the common T allele is associated with lactase persistence. Individuals who are homozygous for C allele are likely to be lactose intolerant.\n",
        "We extracted SNP information from a region of 80k base pairs around the target variant rs4988235 from the 1000 Genomes Project data for all unrelated individuals of CEU population (of European descent).\n",
        "The data is in the form of a VCF file.\n",
        "\n",
        "In this tutorial, you will learn how to:\n",
        "1. read data from VCF file and store it into _ImaGene_ objects,\n",
        "2. run and process simulations to be used for training,\n",
        "3. implement, train and evaluate the neural network,\n",
        "4. deploy the trained network on your genomic data of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pip install memory profiler and memory profiler extension"
      ],
      "metadata": {
        "id": "Ohxm9KNFJlr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory_profiler\n",
        "%load_ext memory_profiler\n"
      ],
      "metadata": {
        "id": "WYM7iqo0JoFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5o3i2z5yk6a"
      },
      "source": [
        "Before starting, we need to load the necessary modules in _python_ ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64eJmTknyk6a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gzip\n",
        "import _pickle as pickle\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import arviz\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models, layers, activations, optimizers, regularizers\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import load_model\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pydot # optional, but required by keras to plot the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CmV6FLRyk6b"
      },
      "source": [
        "... and _ImaGene_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43UVFwfByk6b"
      },
      "outputs": [],
      "source": [
        "%run -i ../ImaGene.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g9dT_ibyk6c"
      },
      "source": [
        "This tutorial has been tested with:\n",
        "* python 3.9.7\n",
        "* numpy 1.19.5\n",
        "* scipy 1.7.1\n",
        "* keras 2.6.0\n",
        "* tensorflow 2.6.0\n",
        "* scikit-image 0.18.3\n",
        "* scikit-learn 1.0\n",
        "* matplotlib 3.4.3\n",
        "* pydot 1.4.2\n",
        "* pymc3 3.11.4\n",
        "* ipython 7.28.0\n",
        "* jupyterlab 3.1.14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exDUTCiNyk6c"
      },
      "source": [
        "### 1. Read data from VCF file and store it into _ImaGene_ objects\n",
        "\n",
        "We store the information of the genomic data into an _ImaFile_ object where we specify the name of the VCF file and the number of samples (i.e. the number of chromosomal copies, twice the number of individuals for a diploid organism).\n",
        "The latter parameter is not strictly necessary but it is useful to check whether the VCF we are analysing contains the data that we expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEdBvKr6yk6c"
      },
      "outputs": [],
      "source": [
        "file_LCT = ImaFile(nr_samples=198, VCF_file_name='LCT.CEU.vcf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQxVlTqZyk6c"
      },
      "source": [
        "We create an _ImaGene_ object by reading the VCF file and generating a matrix of haplotypes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtvUvU0zyk6d"
      },
      "outputs": [],
      "source": [
        "gene_LCT = file_LCT.read_VCF()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V5J7pAxyk6d"
      },
      "source": [
        "An _ImaGene_ has a series of useful methods.\n",
        "For instance, we can have a quick look at the data stored in this object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRdQUYq_yk6d"
      },
      "outputs": [],
      "source": [
        "gene_LCT.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaotJsowyk6d"
      },
      "source": [
        "As expected, we have one image with 198 rows (equivalent to the number of sampled chromosomal copies) and 2200 columns representing all genomic positions reported.\n",
        "It is likely that not all of these positions will be polymorphic in the CEU sample as the VCF file reports variats across all analysed populations.\n",
        "\n",
        "Similarly, we may want to discard rare variants as they may be more associated to errors or be less informative of the scenario we want to predict.\n",
        "Assume that we want to ignore monomorphic sites and singletons for the derived allele.\n",
        "We can accomplish this with the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLCUGIVkyk6e"
      },
      "outputs": [],
      "source": [
        "gene_LCT.filter_freq(0.01);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUUyli6nyk6e"
      },
      "source": [
        "If we are unsure about the ancestral/derived polarisation of alleles, we can convert them into major/minor alleles using the method `.majorminor()`.\n",
        "We can have a look at the resulting image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBCe7K4iyk6e"
      },
      "outputs": [],
      "source": [
        "gene_LCT.plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2pgltogyk6e"
      },
      "source": [
        "As the order on the rows is arbitrary, we can order them (and columns) following several criteria.\n",
        "We can do this with _ImaGene_ with the `.sort` method which has the following options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHhA6lPcyk6e"
      },
      "outputs": [],
      "source": [
        "gene_LCT.sort?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QxKSnlCyk6f"
      },
      "source": [
        "Assume that we wish to sort only rows by their frequency (with the most frequent haplotypes on the top).\n",
        "This can be done with the following command (which will also visualise the resulting image)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEt2cLS2yk6f"
      },
      "outputs": [],
      "source": [
        "gene_LCT.sort('rows_freq');\n",
        "gene_LCT.plot();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q763rDUcyk6f"
      },
      "source": [
        "Once we are happy with our data processing (e.g. filtering and sorting), we need to convert the image into an appropriate format which will be later used for the prediction.\n",
        "As an illustration, we also flip black and white pixels to assign the former to derived (or minor) alleles which is the standard representation of genomic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6mYmhR1yk6f"
      },
      "outputs": [],
      "source": [
        "gene_LCT.convert(flip=True);\n",
        "gene_LCT.plot();\n",
        "gene_LCT.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmHJRGlnyk6f"
      },
      "source": [
        "We finally note that our image has 192 columns now, representing the number of retained SNPs.\n",
        "\n",
        "We can save our _ImaGene_ object in the working `path` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTp_nkMIyk6f"
      },
      "outputs": [],
      "source": [
        "# set as appropriate, e.g.:\n",
        "# path='/home/mfumagal/Data/ImaGene/Tutorials/Data/' # my local machine\n",
        "# path = './' # for workshop spp1819\n",
        "path = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deUVNgyhyk6g"
      },
      "outputs": [],
      "source": [
        "gene_LCT.save(file=path + 'gene_LCT');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBwjzQedyk6g"
      },
      "source": [
        "As an illustration, the following line will load the _ImaGene_ object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cx8YMrzyk6g"
      },
      "outputs": [],
      "source": [
        "gene_LCT = load_imagene(file=path + 'gene_LCT');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMNtBrumyk6g"
      },
      "source": [
        "### 2. Run and process simulations to be used for training the neural network\n",
        "\n",
        "_ImaGene_ provides users with an easy interface with _msms_ to run simulations which will be used for training the network.\n",
        "The script `../generate_dataset.sh` accepts an input file which specifies the parameters of the simulations.\n",
        "A generic file with all descriptions is `../params.txt`.\n",
        "If you want to make changes, you need to open the parameter file, change the value of the desired options, save and close it.\n",
        "\n",
        "We provide an example of this file called `params_binary` which simulates a total of 200,000 loci of 80kbp either under neutral evolution or positive selection with additive effect and an allelic selection coefficient of $1.5$\\% targeting a variant in the middle of the region.\n",
        "Selection starts 800 generations ago (corresponding to 20kya with a generation time of 25 years) with an allele frequency of $0.01$.\n",
        "We impose a mutation rate is $1.5e-8$ per base per generation and a recombination rate of $1e-8$.\n",
        "Finally, the simulated population follows a 3-epoch model of bottleneck and expansion as proposed by [Marth et al. 2004](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1470693/) for a European population.\n",
        "We sampled 198 chromosomal copies to match our observed data.\n",
        "\n",
        "After we specify the directories for _msms_ and the folder where all the simulations will be stored, we can run the following command to perform the simulations. This script will split the simulations into different batches to later perform training with a \"simulation-on-the-fly\" approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPZzUtnryk6g"
      },
      "outputs": [],
      "source": [
        "# if you wish to generate new training data, do not run otherwise\n",
        "import subprocess\n",
        "subprocess.call(\"bash ../generate_dataset.sh params_binary.txt\".split());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaPSwBctyk6g"
      },
      "source": [
        "Let's perform the first iteration of training.\n",
        "To do that, we need to read the first batch of simulations in `[..]/Binary/Simulations1`and store them into an _ImaFile_ object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tFfr0Hmyk6g"
      },
      "outputs": [],
      "source": [
        "# set as appropriate, e.g.:\n",
        "# path_sim='/home/mfumagal/Data/ImaGene/Tutorials/' # my local machine\n",
        "# path_sim='/mnt/quobyte/ImaGene/' # for workshop spp1819\n",
        "path_sim = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlCz4uf0yk6g"
      },
      "outputs": [],
      "source": [
        "file_sim = ImaFile(simulations_folder=path_sim + 'Binary/Simulations1', nr_samples=198, model_name='Marth-3epoch-CEU');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Z8El-8yk6h"
      },
      "source": [
        "Then, we populate an _ImaGene_ object by specifying the variable we want to estimate/predict (`selection_coeff_hetero`) and how many data points per class we wish to retain.\n",
        "As a quick example, we will use only 2000 data points per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m-gkHk7yk6h"
      },
      "outputs": [],
      "source": [
        "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwz0-XrRyk6h"
      },
      "source": [
        "We can have a look at the data stored in this object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3k2xy_Zyk6h"
      },
      "outputs": [],
      "source": [
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQbZ9lVAyk6h"
      },
      "source": [
        "We have 4000 images in this object. Recall that with the first line we simulated 2 classes and retained 2000 data points for each class. All images have 198 rows as expected, as this represents the number of simulated haplotypes. However, images have different number of columns, ranging from $\\approx 130$ to $\\approx 450$ with an average value of $\\approx 295$. The number of columns represents the number of polymorphic sites and fixed derived alleles in a _msms_ file. This number may vary from simulated gene to another.\n",
        "Our observed data for LCT has 192 columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olg1Q7HLyk6h"
      },
      "source": [
        "As mentioned before, _ImaGene_ provides functionalities to manipulate our data. Specifically we can do the following:\n",
        "* convert ancestral/derived to major/minor allele polarisation\n",
        "* filter out columns based on a minimum allele frequency (e.g. 0.01)\n",
        "* sorting rows and columns by frequency (or genetic distance from the most frequent entry)\n",
        "\n",
        "We need to follow the same data processing as the one employed for the real data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ekdXajAyk6q"
      },
      "outputs": [],
      "source": [
        "gene_sim.filter_freq(0.01);\n",
        "gene_sim.sort('rows_freq');\n",
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8zBzedjyk6q"
      },
      "source": [
        "All images must have the same dimensions. You can explore all different options for resizing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcTEe1xfyk6r"
      },
      "outputs": [],
      "source": [
        "?gene_sim.resize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fktRoFAhyk6r"
      },
      "source": [
        "One possibility would be to resize them to match the dimensions of the real data.\n",
        "In this case it means resize all images to have shape (198, 192) which can be achieved with the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uLYnuTCyk6r"
      },
      "outputs": [],
      "source": [
        "gene_sim.resize((198, 192));\n",
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLv1aCgmyk6s"
      },
      "source": [
        "After the data manipulation is done, we need to convert images to proper _numpy_ float matrices,as previously discussed. The following line will do the job (including flipping black/white pixels).\n",
        "Note that the `.convert` method allows you to normalise the data too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jlH8bqSyk6s"
      },
      "outputs": [],
      "source": [
        "gene_sim.convert(flip=True);\n",
        "gene_sim.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKKPlEVryk6s"
      },
      "source": [
        "Note that in addition to the genomic data, an _ImaGene_ object contains information on the corresponding targets (in this case the selection coefficient, either 0 or 300 in $2N_e$ units with $N_e = 10000$).\n",
        "As an illustration, let's plot one random image per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaMAyHSWyk6s"
      },
      "outputs": [],
      "source": [
        "for sel in gene_sim.classes:\n",
        "    print(sel)\n",
        "    gene_sim.plot(np.where(gene_sim.targets == sel)[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUctBaYMyk6t"
      },
      "source": [
        "Finally we need to randomly shuffle our images before using them for training our network.\n",
        "We can easily accomplish this with the following line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqAWDuCFyk6t"
      },
      "outputs": [],
      "source": [
        "gene_sim.subset(get_index_random(gene_sim));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1y1tU2Fyk6t"
      },
      "source": [
        "Our targets represent the 2 possible classes. However, since we are doing a binary classification, we need to vectorise them as required by _keras_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1MWlnpQyk6t"
      },
      "outputs": [],
      "source": [
        "gene_sim.targets = to_binary(gene_sim.targets);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNTOES-pyk6t"
      },
      "source": [
        "The object is now ready to be used for the classification!\n",
        "You can save it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpz4Q8FByk6u"
      },
      "outputs": [],
      "source": [
        "gene_sim.save(file=path + 'gene_sim.binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPoQvJLVyk6u"
      },
      "source": [
        "If you want to load an _ImaGene_ object you can use the following function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9mWBM8Qyk6u"
      },
      "outputs": [],
      "source": [
        "gene_sim = load_imagene(file=path + 'gene_sim.binary')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "# Add any other imports you don't already have, such as TensorFlow related ones if not present\n"
      ],
      "metadata": {
        "id": "tR_CITbM2HqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and fucntions to measure epoch time and training time"
      ],
      "metadata": {
        "id": "7ZS6fJPV7Nlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tensorflow.keras import models, layers, regularizers, callbacks\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "class TimeHistory(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.times = []\n",
        "        self.total_time = time.time()\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs=None):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs=None):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        self.total_time = time.time() - self.total_time"
      ],
      "metadata": {
        "id": "MUs3yYNm7RZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE8NcYXgyk6u"
      },
      "source": [
        "### 3. Implement, train and evaluate the neural network\n",
        "\n",
        "Now that our data is ready, we can build our network.\n",
        "Specifically, we can build a model in _keras_ with convolutional, pooling and dense layers.\n",
        "In this example we have 3 layers of 2D convolutions and pooling followed by a fully-connected layer.\n",
        "We just need to specify the dimensions of the data in the first layer, and this is specified by the option `input_shape=gene_sim.data.shape[1:]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-M0lesKyk6v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.profiler.model_analyzer import profile\n",
        "from tensorflow.python.profiler.option_builder import ProfileOptionBuilder\n",
        "\n",
        "def get_flops(model):\n",
        "    forward_pass = tf.function(model.call, input_signature=[tf.TensorSpec(shape=(1,) + model.input_shape[1:])])\n",
        "    graph_info = profile(forward_pass.get_concrete_function().graph, options=ProfileOptionBuilder.float_operation())\n",
        "    flops = graph_info.total_float_ops\n",
        "    return flops\n",
        "\n",
        "\n",
        "model = models.Sequential([\n",
        "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid', input_shape=gene_sim.data.shape[1:]),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
        "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                    layers.Flatten(),\n",
        "                    layers.Dense(units=128, activation='relu'),\n",
        "                    layers.Dense(units=1, activation='sigmoid')])\n",
        "\n",
        "\n",
        "flops = get_flops(model)\n",
        "macs = flops / 2\n",
        "print(f\"MACs: {macs:,} (Multiply-Accumulate Operations)\")\n",
        "print(f\"FLOPs: {flops:,} (Floating Point Operations)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NaVKMhJyk6v"
      },
      "source": [
        "Then, let's compile our _keras_ model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9AblWa4yk6v"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the number of paramters in the model"
      ],
      "metadata": {
        "id": "PehiwttdGTn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `model` is your compiled model\n",
        "total_params = model.count_params()\n",
        "print(f\"Total Parameters: {total_params}\")\n"
      ],
      "metadata": {
        "id": "1scZH_YpGXSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV2M_7mVyk6v"
      },
      "source": [
        "Let's look at a summary of the model and plot it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdEBQ3rRyk6v"
      },
      "outputs": [],
      "source": [
        "model.summary()\n",
        "plot_model(model, path + 'net.binary.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SBkMGa1yk6w"
      },
      "outputs": [],
      "source": [
        "%%memit\n",
        "time_callback = TimeHistory()\n",
        "score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10, callbacks=[time_callback])\n",
        "print(f\"Total training time for initial batch: {time_callback.total_time}s\")\n",
        "print(f\"Average epoch time for initial batch: {sum(time_callback.times) / len(time_callback.times) if time_callback.times else 0}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mImkGnd7yk6w"
      },
      "source": [
        "Remember that you can save a _keras_ model with `model.save('net.h5')`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcyaDDiyyk6w"
      },
      "source": [
        "Now we can initialise a network object _ImaNet_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd5TdN_Qyk6w"
      },
      "outputs": [],
      "source": [
        "net_LCT = ImaNet(name='[C32+P]x2+[C64+P]+D128')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIgy9LgKyk6w"
      },
      "source": [
        "We can keep track of scores (loss and accuracy) across iterations with `.update_scores`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSV-hfWEyk6w"
      },
      "outputs": [],
      "source": [
        "net_LCT.update_scores(score);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTTeXolVyk6x"
      },
      "source": [
        "Now we need to repeat the whole procedure described above using all remaning batches of data, leaving the last one for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LCnBmtGyk6x"
      },
      "outputs": [],
      "source": [
        "i = 2\n",
        "while i < 10:\n",
        "    print(f\"Processing batch {i}\")\n",
        "\n",
        "    # Load and preprocess the data for the current batch\n",
        "    file_sim = ImaFile(simulations_folder=path_sim + 'Binary/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
        "\n",
        "    gene_sim.filter_freq(0.01)\n",
        "    gene_sim.sort('rows_freq')\n",
        "    gene_sim.resize((198, 192))\n",
        "    gene_sim.convert(flip=True)\n",
        "\n",
        "    gene_sim.subset(get_index_random(gene_sim))\n",
        "    gene_sim.targets = to_binary(gene_sim.targets)\n",
        "\n",
        "    # Initialize TimeHistory for the current training session\n",
        "    time_callback = TimeHistory()\n",
        "\n",
        "    # Train the model on the current batch with the TimeHistory callback\n",
        "    score = model.fit(gene_sim.data, gene_sim.targets, batch_size=64, epochs=1, verbose=1, validation_split=0.10, callbacks=[time_callback])\n",
        "\n",
        "    # Update ImaNet scores with the latest training session's results\n",
        "    net_LCT.update_scores(score)\n",
        "\n",
        "    # Reporting time metrics for the current batch\n",
        "    total_training_time = time_callback.total_time\n",
        "    average_epoch_time = sum(time_callback.times) / len(time_callback.times) if time_callback.times else 0\n",
        "    print(f\"Total training time for batch {i}: {total_training_time}s\")\n",
        "    print(f\"Average epoch time for batch {i}: {average_epoch_time}s\")\n",
        "\n",
        "    i += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrF4rmlpyk6x"
      },
      "source": [
        "We can plot loss and validation accuracy during the training to check, for instance, for overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFPPoVKEyk6x"
      },
      "outputs": [],
      "source": [
        "net_LCT.plot_train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIZT_BZZyk6x"
      },
      "source": [
        "We save (and/or load) the final trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxwECW09yk6x"
      },
      "outputs": [],
      "source": [
        "model.save(path + 'model.binary.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKSZ4Yb9yk6y"
      },
      "outputs": [],
      "source": [
        "model = load_model(path + 'model.binary.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfeg7dlOyk6y"
      },
      "source": [
        "You can also save the network itself (and load it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iCcNFOXyk6y"
      },
      "outputs": [],
      "source": [
        "net_LCT.save(path + 'net_LCT.binary');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axRE30dNyk6y"
      },
      "outputs": [],
      "source": [
        "net_LCT = load_imanet(path + 'net_LCT.binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9MEuoS5yk6y"
      },
      "source": [
        "Finally, we evaluate the training on the testing dataset, i.e. the last batch of simulated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN-V4-b3yk6y"
      },
      "outputs": [],
      "source": [
        "i = 10\n",
        "file_sim = ImaFile(simulations_folder=path_sim + 'Binary/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
        "gene_sim_test = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=2000)\n",
        "\n",
        "gene_sim_test.filter_freq(0.01)\n",
        "gene_sim_test.sort('rows_freq')\n",
        "gene_sim_test.resize((198, 192))\n",
        "gene_sim_test.convert(flip=True)\n",
        "\n",
        "rnd_idx = get_index_random(gene_sim_test) # no need to create this extra variable\n",
        "gene_sim_test.subset(rnd_idx)\n",
        "\n",
        "gene_sim_test.targets = to_binary(gene_sim_test.targets);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4PfJ4UXyk6z"
      },
      "source": [
        "Let's report loss and accuracy on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8KfedyIyk6z"
      },
      "outputs": [],
      "source": [
        "net_LCT.test = model.evaluate(gene_sim_test.data, gene_sim_test.targets, batch_size=None, verbose=0)\n",
        "print(net_LCT.test) # it will report [loss, accuracy]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate and plot the ROC Curve and AUC score for the model on the testing set."
      ],
      "metadata": {
        "id": "DpeO8kTHHm7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Calculate and plot the ROC Curve and AUC score for the model on the testing set.\"\"\"\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict probabilities for the test set\n",
        "prob_predictions = model.predict(gene_sim_test.data).ravel()\n",
        "\n",
        "# Calculate ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(gene_sim_test.targets, prob_predictions)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HinUm4RGHoHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1qT9nGnyk6z"
      },
      "source": [
        "For a binary (or multiclass) classification, it is convenient to plot the confusion matrix after predicting the responses from the testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4rweHd0yk6z"
      },
      "outputs": [],
      "source": [
        "# Predicting the classes using the model\n",
        "net_LCT.predict(gene_sim_test, model)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "net_LCT.plot_cm(gene_sim_test.classes, text=True)\n",
        "\n",
        "# Extracting the predictions made by the model\n",
        "predicted_classes = net_LCT.values[1,:]\n",
        "\n",
        "# Extracting the true class labels from the test data\n",
        "true_classes = gene_sim_test.targets\n",
        "\n",
        "# Importing the necessary functions from sklearn to calculate precision, recall, and F1 score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculating the precision\n",
        "precision = precision_score(true_classes, predicted_classes)\n",
        "\n",
        "# Calculating the recall\n",
        "recall = recall_score(true_classes, predicted_classes)\n",
        "\n",
        "# Calculating the F1 score\n",
        "f1 = f1_score(true_classes, predicted_classes)\n",
        "\n",
        "# Printing out the precision, recall, and F1 score\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mfq-uJ8yk6z"
      },
      "source": [
        "### 4. Deploy the trained network on your genomic data of interest\n",
        "\n",
        "Finally we can use the trained network to predict natural selection on our locus of interest.\n",
        "The output of this command will give us the class score (e.g. this can be interpreted as a posterior probability with uniform prior) of said locus under positive selection under the conditions we simulated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJc_dD8_yk60"
      },
      "outputs": [],
      "source": [
        "# Measure single inference time with TensorFlow deciding the batch size\n",
        "start_time = time.time()\n",
        "# Predicting a single instance without explicitly setting the batch size\n",
        "prediction = model.predict(gene_LCT.data[0:0], batch_size=None)\n",
        "single_inference_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch inference for entire dataset"
      ],
      "metadata": {
        "id": "K8P5Md8-DsPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure batch inference time with TensorFlow deciding the batch size\n",
        "batch_start_time = time.time()\n",
        "# Predicting on the entire dataset without explicitly setting the batch size\n",
        "predictions = model.predict(gene_LCT.data, batch_size=None)\n",
        "batch_inference_time = time.time() - batch_start_time\n",
        "print(f\"Batch inference time (with auto batch size) for {len(gene_LCT.data)} instances: {batch_inference_time}s\")\n"
      ],
      "metadata": {
        "id": "KOCyH9DTD3aL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}